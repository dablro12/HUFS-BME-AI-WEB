{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils.dataset import CustomDataset\n",
    "from torchsampler import ImbalancedDatasetSampler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "import numpy as np \n",
    "\n",
    "import random\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "from torch.nn import functional as F \n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_img_dir = '/mnt/HDD/octc/mask_abstract/train'\n",
    "tr_mask_dir = '/mnt/HDD/octc/mask_abstract/mask' \n",
    "vl_img_dir = '/mnt/HDD/octc/mask_abstract/test'\n",
    "vl_mask_dir = '/mnt/HDD/octc/mask_abstract/mask'\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.GaussianBlur(3, sigma=(0.1, 2.0)),\n",
    "    transforms.RandomAdjustSharpness(0.5),\n",
    "    transforms.RandomAutocontrast(0.5),\n",
    "    transforms.ColorJitter(0.05, 0.05, 0.05, 0.05),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "valid_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "train_dataset = CustomDataset(\n",
    "    image_dir = tr_img_dir,\n",
    "    mask_dir = tr_mask_dir,\n",
    "    transform= train_transform,\n",
    "    mask_transform= None,\n",
    "    testing= False,\n",
    "    mask_shuffle = True,\n",
    ")\n",
    "valid_dataset = CustomDataset(\n",
    "    image_dir = vl_img_dir,\n",
    "    mask_dir = vl_mask_dir,\n",
    "    transform= valid_transform,\n",
    "    mask_transform= None,\n",
    "    testing = True,\n",
    "    mask_shuffle = False,\n",
    ")\n",
    "tr_batch, vl_batch = 6, 2\n",
    "train_loader = DataLoader(dataset = train_dataset, batch_size = tr_batch, shuffle = True)\n",
    "\n",
    "valid_loader = DataLoader(dataset = valid_dataset, batch_size = vl_batch, shuffle = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting(images, masks, input_images):\n",
    "    plt.figure(dpi =256)\n",
    "    plt.subplot(131)\n",
    "    plt.imshow(images[1,0], cmap= 'gray')\n",
    "    plt.title('image[GT]')\n",
    "    plt.subplot(132)\n",
    "    plt.imshow(masks[1,0 ], cmap= 'gray')\n",
    "    plt.title('mask')\n",
    "    plt.subplot(133)\n",
    "    plt.imshow(input_images[1,0 ], cmap= 'gray')\n",
    "    plt.title('input_image')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, masks in train_loader:\n",
    "    # mask가 0이 아닌 부분에 대해 image를 mask로 대체\n",
    "    input_images = images.clone()\n",
    "    # mask와 input_images shape이 같아야하므로 mask를 image shape으로 resize\n",
    "    print(images.shape, masks.shape)\n",
    "    input_images[masks != 0] = masks[masks != 0] \n",
    "    # input_images 처리해줫으니 다시 masks를 1채널로 변경\n",
    "    masks = masks[:,0,:,:].unsqueeze(1)\n",
    "\n",
    "    plotting(images, masks, input_images)\n",
    "    break\n",
    "for images, masks, paths in valid_loader:\n",
    "    # mask가 0이 아닌 부분에 대해 image를 mask로 대체\n",
    "    input_images = images.clone()\n",
    "    # mask와 input_images shape이 같아야하므로 mask를 image shape으로 resize\n",
    "    input_images[masks != 0] = masks[masks != 0] \n",
    "        \n",
    "    # input_images 처리해줫으니 다시 masks를 1채널로 변경\n",
    "    masks = masks[:,0,:,:].unsqueeze(1)\n",
    "    plotting(images, masks, input_images)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.aotgan import InpaintGenerator, Discriminator\n",
    "netG = InpaintGenerator()\n",
    "netD = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "from loss.loss import L1, Perceptual, Style, smgan \n",
    "import torch.optim as optim\n",
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# device = 'cpu'\n",
    "\n",
    "netG = InpaintGenerator().to(device)\n",
    "netD = Discriminator().to(device)\n",
    "G_check = torch.load('/mnt/HDD/oci_models/aotgan/premodel/G0000000.pt')\n",
    "D_check = torch.load('/mnt/HDD/oci_models/aotgan/premodel/D0000000.pt') #<-- Discriminator is not needed\n",
    "O_check = torch.load('/mnt/HDD/oci_models/aotgan/premodel/O0000000.pt')\n",
    "\n",
    "netG.load_state_dict(G_check)\n",
    "\n",
    "netD = Discriminator().to(device)\n",
    "optimG = optim.Adam(params= netG.parameters(), lr = 0.0001, betas = (0, 0.9))\n",
    "optimD = optim.Adam(params= netD.parameters(), lr = 0.0001, betas = (0, 0.9))\n",
    "optimG.load_state_dict(O_check['optimG'])\n",
    "optimD.load_state_dict(O_check['optimD'])\n",
    "\n",
    "g_loss_1 = L1()\n",
    "g_loss_2 = Perceptual()\n",
    "g_loss_3 = Style()\n",
    "loss_gan = smgan()\n",
    "\n",
    "def G_LOSS(Adv, L1, Per, Style, w1 = 0.01, w2=1 , w3 = 0.1, w4 = 100):\n",
    "    \"\"\"\n",
    "    Adv Loss / L1 / Perceptual / Style\n",
    "    \"\"\"\n",
    "    return Adv*w1 + L1*w2 + Per*w3 + Style*w4\n",
    "\n",
    "metrics = {\n",
    "    't_g_loss':[],\n",
    "    't_d_loss':[],\n",
    "    'v_g_loss':[],\n",
    "    'v_d_loss':[],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_validation(labels, masks, input_images, pred_images, pred_masks, comp_images,  epoch, save_dir):\n",
    "    plt.figure(dpi=128)\n",
    "    plt.subplot(231)\n",
    "    plt.imshow(labels[0, 0].cpu().detach().numpy(), cmap='gray')\n",
    "    plt.title(\"original\")\n",
    "    plt.subplot(232)\n",
    "    plt.imshow(masks[0, 0].cpu().detach().numpy(), cmap='gray')\n",
    "    plt.title(\"mask\")\n",
    "    plt.subplot(233)\n",
    "    plt.imshow(input_images[0, 0].cpu().detach().numpy(), cmap='gray')\n",
    "    plt.title('input image')\n",
    "    plt.subplot(234)\n",
    "    plt.imshow(pred_images[0, 0].cpu().detach().numpy(), cmap='gray')\n",
    "    plt.title('pred before image')\n",
    "    plt.subplot(235)\n",
    "    plt.imshow(pred_masks[0, 0].cpu().detach().numpy(), cmap='gray')\n",
    "    plt.title('pred Discriminator mask')\n",
    "    plt.subplot(236)\n",
    "    plt.imshow(comp_images[0, 0].cpu().detach().numpy(), cmap='gray')\n",
    "    plt.title('Result image')\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(os.path.join(save_dir, f'epoch_{epoch}.png'))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def save_model(netG, netD, optimG, optimD, epoch, save_dir):\n",
    "    torch.save({\n",
    "        'netG': netG.state_dict(),\n",
    "        'netD': netD.state_dict(),\n",
    "        'optimG': optimG.state_dict(),\n",
    "        'optimD': optimD.state_dict()\n",
    "    }, os.path.join(save_dir, f'epoch_{epoch}.pt'))\n",
    "\n",
    "def save_loss(metrics, save_dir):\n",
    "    # loss plot\n",
    "    plt.figure(dpi=128)\n",
    "    for key, value in metrics.items():\n",
    "        plt.plot(value, label=key)\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(save_dir, 'loss.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    np.save(os.path.join(save_dir, 'metrics.npy'),metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_path = '/mnt/HDD/oci_models/aotgan/240505'\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "for epoch in range(30):\n",
    "    t_g_losses, t_d_losses, v_g_losses, v_d_losses = 0., 0., 0., 0.\n",
    "    \n",
    "    netG.train()\n",
    "    netD.train()\n",
    "    for images, masks in train_loader:\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "        \n",
    "        ### 전처리 \n",
    "        # mask가 0이 아닌 부분에 대해 image를 mask로 대체\n",
    "        input_images = images.clone()\n",
    "        # mask와 input_images shape이 같아야하므로 mask를 image shape으로 resize\n",
    "        input_images[masks != 0] = masks[masks != 0] \n",
    "\n",
    "        # input_images 처리해줫으니 다시 masks를 1채널로 변경\n",
    "        masks = masks[:,0,:,:].unsqueeze(1)\n",
    "        \n",
    "        # 입력이미지 device 할당 \n",
    "        input_images = input_images.to(device) \n",
    "    \n",
    "        ### Training\n",
    "        pred_images = netG(input_images, masks)\n",
    "        \n",
    "        ## mask에서 0이 아닌 부분을 GT로 대체, 이때 마스크는 0~1사이의 값을 가짐 \n",
    "        masks = masks.repeat(1,3,1,1)\n",
    "        comp_images = images.clone()\n",
    "        comp_images[masks != 0] = pred_images[masks != 0]\n",
    "        masks = masks[:,0,:,:].unsqueeze(1)\n",
    "\n",
    "        l1 = g_loss_1(pred_images, images)\n",
    "        l2 = g_loss_2(pred_images, images)\n",
    "        l3 = g_loss_3(pred_images, images)\n",
    "        pred_masks, (d_loss, adv_loss) = loss_gan(netD=netD, fake=comp_images, real=images, masks=masks)\n",
    "        g_loss = G_LOSS(adv_loss, l1, l2, l3)\n",
    "        \n",
    "        optimG.zero_grad()\n",
    "        optimD.zero_grad()\n",
    "        \n",
    "        g_loss.backward()\n",
    "        d_loss.backward()\n",
    "        \n",
    "        optimG.step()\n",
    "        optimD.step()\n",
    "        \n",
    "        t_g_losses += g_loss.cpu().detach().item()\n",
    "        t_d_losses += d_loss.cpu().detach().item()\n",
    "        \n",
    "        print(images.shape)\n",
    "        print(masks.shape)\n",
    "        print(input_images.shape)\n",
    "        print(pred_images.shape)\n",
    "        print(comp_images.shape)\n",
    "    with torch.no_grad():\n",
    "        netG.eval()\n",
    "        netD.eval()\n",
    "        for images, masks, paths in valid_loader:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            ### 전처리\n",
    "            # mask가 0이 아닌 부분에 대해 image를 mask로 대체\n",
    "            input_images = images.clone()\n",
    "            # mask와 input_images shape이 같아야하므로 mask를 image shape으로 resize\n",
    "            input_images[masks != 0] = masks[masks != 0] \n",
    "            # input_images 처리해줫으니 다시 masks를 1채널로 변경\n",
    "            masks = masks[:,0,:,:].unsqueeze(1)\n",
    "            # 입력이미지 device 할당\n",
    "            input_images = input_images.to(device) \n",
    "\n",
    "            ### inference\n",
    "            pred_images = netG(input_images, masks)  # 3+1ch\n",
    "            \n",
    "            ## mask에서 0이 아닌 부분을 GT로 대체, 이때 마스크는 0~1사이의 값을 가짐 \n",
    "            masks = masks.repeat(1,3,1,1)\n",
    "            comp_images = images.clone()\n",
    "            comp_images[masks != 0] = pred_images[masks != 0]\n",
    "            masks = masks[:,0,:,:].unsqueeze(1)\n",
    "\n",
    "\n",
    "            l1 = g_loss_1(pred_images, images)\n",
    "            l2 = g_loss_2(pred_images, images)\n",
    "            l3 = g_loss_3(pred_images, images)\n",
    "            pred_masks, (d_loss, adv_loss) = loss_gan(netD=netD, fake=comp_images, real=images, masks=masks)\n",
    "            g_loss = G_LOSS(adv_loss, l1, l2, l3)\n",
    "            \n",
    "            v_g_losses += g_loss.cpu().detach().item()\n",
    "            v_d_losses += d_loss.cpu().detach().item()\n",
    "    if epoch % 5 == 0:\n",
    "        save_validation(images, masks, input_images, pred_images, pred_masks, comp_images,  epoch, save_dir = save_path)\n",
    "        save_model(netG, netD, optimG, optimD, epoch, save_dir = save_path)\n",
    "        save_loss(metrics, save_dir = save_path)\n",
    "\n",
    "    metrics['t_g_loss'].append(t_g_losses / len(train_loader))\n",
    "    metrics['t_d_loss'].append(t_d_losses / len(train_loader))\n",
    "    metrics['v_g_loss'].append(v_g_losses / len(valid_loader))\n",
    "    metrics['v_d_loss'].append(v_d_losses / len(valid_loader))\n",
    "\n",
    "    print(\"#\" * 100)    \n",
    "    print(f\"Train - G LOSS : {metrics['t_g_loss'][-1]} | {metrics['t_d_loss'][-1]}\\n\")\n",
    "    print(f\"Valid - D LOSS : {metrics['v_g_loss'][-1]} | {metrics['v_d_loss'][-1]}\\n\")\n",
    "    print(\"#\" * 100)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
